◀️ [Home](../README.md)

# Random Concepts

## AI

### Generative AI vs LLMs
Generative artificial intelligence, which is commonly referred to as gen AI, is a subset of artificial intelligence that is capable of creating text, images, or other data using generative models, often in response to prompts.

**Generative AI** encompasses a broader range of models capable of generating various types of content beyond just text, while **LLM** specifically refers to a subset of generative AI models focusing on language tasks.

While both terms describe AI models capable of generating human-like responses based on input prompts in many references, it's important to note they're not identical.

### LLMs
Large language models are highly sophisticated computer programs trained on gigantic amounts of data that can be text or images. LLMs refer to large, general-purpose language models that can be pre-trained and then fine-tuned for specific purposes.

In this context, large refers to: The size of the training dataset, which can sometimes be at the petabyte scale. And the number of parameters. Parameters are the memories and knowledge that the machine has learned during model training.

#### Prompts
When you submit a prompt to an LLM, it calculates the probability of the correct answer from its pre-trained model. The probability is determined through a task called pre-training. In this way, the LLM works like a fancy autocomplete, suggesting the most common correct response to the prompt.

#### Hallucinations
Hallucinations are words or phrases that are generated by the model that are often nonsensical or grammatically incorrect. This happens because LLMs can only understand the information they were trained on.

## Algorithm
Piece of code that does an interesting thing.

## Bootstrap
Refers to the initial process of setting up an application or system when it starts. Specifically, it refers to the time and resources required for the application to load and become fully operational after it is triggered or launched. This process can include tasks like loading dependencies, initializing configurations, connecting to databases, and preparing the application to handle requests.

To mitigate the impact of long startup times (especially in serverless or cloud environments), you can pre-warm instances, meaning that the application is kept alive and ready to handle traffic without having to go through the bootstrap process every time a new request is made. This helps reduce the delay that could occur when an instance is started from scratch (often referred to as cold start).

## CI/CD
**Continuous Integration** and **Continuous Deployment (or Delivery)** is a set of practices and tools in software development aimed at automating and improving the process of delivering software. 

> **Automates and streamlines the development, testing, and deployment process, enabling faster and more reliable software delivery.**

### **Continuous Integration (CI)**

CI is the practice of frequently integrating code changes into a shared repository, followed by automated builds and tests to detect errors early.

**Key Features**:

1.	Developers push code changes frequently (e.g., daily).

2.	Automated systems build and test the code after each change.

3.	Ensures new code integrates well with the existing codebase.

4.	Catches bugs early, improving overall software quality.

**Tools**: Jenkins, GitHub Actions, GitLab CI, Travis CI.

### **Continuous Deployment (CD)**

CD extends CI by automating the process of deploying code to production or other environments after it passes all tests.

#### **Key Features**:

1.	Deployment happens automatically (or semi-automatically) after successful tests.

2.	Ensures faster delivery of new features and bug fixes to users.

3.	Reduces human intervention, minimizing errors in the deployment process.

#### **Two Variants**:

- **Continuous Delivery**: Code is always ready for deployment, but deployment may require manual approval.

- **Continuous Deployment**: Code is automatically deployed to production after passing all checks.

**Tools**: AWS CodePipeline, Azure DevOps, GitHub Actions, CircleCI.

### **Benefits of CI/CD**

1.	**Faster Development Cycles**: Code changes are quickly tested and deployed.

2.	**Higher Code Quality**: Automated tests ensure fewer bugs reach production.

3.	**Reduced Risks**: Small, incremental updates are easier to test and rollback if needed.

4.	**Increased Collaboration**: Teams integrate and share changes more frequently.

## Prompting
A prompt is a specific instruction, question, or cue given to a computer. In other words, it is the text that you feed to the model. Prompt engineering is a way of articulating your prompts to get the best response from the model. The better structured a prompt is, the better the output from the model will be.

### Types
Prompts can be in the form of a question, and are categorized into four categories: 

- **Zero-shot** prompts do not contain any context or examples to assist the model.

- **One-shot** prompts, however, provide one example to the model for context.

- **Few-shot** prompts provide at least two examples to the model for context.

- **Role** prompts require a frame of reference for the model to work from as it answers the questions.

### Elements
The two elements of a prompt: the preamble and the input. 
- The **preamble** refers to the introductory text you provide to give the model context and instructions before your main question or request. 
- The **input** is the central request you're making to the LLM. It’s what the instruction or task will act upon.

### Best Practices
1. Write detailed and explicit instructions. Be clear and concise in the prompts that you feed into the model.
2. Be sure to define boundaries for the prompt. It’s better to instruct the model on what to do rather than what not to do.
3. Adopt a persona for your input. Adding a persona for the model can provide meaningful context to help it focus on related questions, which can help improve accuracy.
4. It’s a recommended practice to keep each sentence concise. Longer sentences can sometimes produce suboptimal results.

## Unit Tests

A **unit test** is a type of software testing that focuses on verifying the correctness of individual units or components of a program. A “unit” typically refers to the smallest piece of code that can be tested in isolation, such as a function, method, or class.

### **Key Characteristics**

1.	**Small Scope**:

- Tests a single function, method, or class without external dependencies.

2.	**Automation**:

- Written as code and executed automatically, often using a testing framework (e.g., unittest, pytest in Python, or JUnit in Java).

3.	**Isolation**:

- Focuses only on the unit being tested. Mocking or stubbing is used to simulate dependencies.

4.	**Fast Execution**:

- Runs quickly, making it practical for frequent execution during development.

### **Purpose**

- Ensure that individual components work as intended.

- Catch bugs early in the development process.

- Provide documentation of how a unit is expected to behave.

- Facilitate refactoring by ensuring the code’s correctness before and after changes.

### Example

```python
def add(a, b):
    return a + b
```

A unit test for the function above might look like this:

```python
import unittest

class TestMathFunctions(unittest.TestCase):
    def test_add(self):
        self.assertEqual(add(2, 3), 5)
        self.assertEqual(add(-1, 1), 0)
        self.assertEqual(add(0, 0), 0)

if __name__ == "__main__":
    unittest.main()
```